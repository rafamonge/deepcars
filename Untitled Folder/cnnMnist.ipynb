{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "Note: this file uses tensorflow 1.2, which adds direct support for eras. If you are using an older version with plain keras, you can just remove the tensorflow.contrib.keras.python and replace with regular keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.keras.python import keras\n",
    "from tensorflow.contrib.keras.python.keras.datasets import mnist\n",
    "from tensorflow.contrib.keras.python.keras.models  import Sequential\n",
    "from tensorflow.contrib.keras.python.keras.layers  import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.contrib.keras.python.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1671)  # for reproducibility\n",
    "\n",
    "# network and training\n",
    "NB_EPOCH = 200\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10   # number of outputs = number of digits\n",
    "OPTIMIZER = keras.optimizers.SGD() # SGD optimizer, explained later in this chapter\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 56s - loss: 0.3473 - acc: 0.8943 - val_loss: 0.0884 - val_acc: 0.9738\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 56s - loss: 0.1258 - acc: 0.9632 - val_loss: 0.0600 - val_acc: 0.9803\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 56s - loss: 0.0997 - acc: 0.9707 - val_loss: 0.0484 - val_acc: 0.9848\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 56s - loss: 0.0839 - acc: 0.9759 - val_loss: 0.0442 - val_acc: 0.9857\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 56s - loss: 0.0720 - acc: 0.9785 - val_loss: 0.0445 - val_acc: 0.9855\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 56s - loss: 0.0680 - acc: 0.9793 - val_loss: 0.0368 - val_acc: 0.9878\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 56s - loss: 0.0640 - acc: 0.9818 - val_loss: 0.0347 - val_acc: 0.9880\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 56s - loss: 0.0595 - acc: 0.9825 - val_loss: 0.0353 - val_acc: 0.9880\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 56s - loss: 0.0567 - acc: 0.9830 - val_loss: 0.0329 - val_acc: 0.9879\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 56s - loss: 0.0545 - acc: 0.9838 - val_loss: 0.0312 - val_acc: 0.9891\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 56s - loss: 0.0521 - acc: 0.9845 - val_loss: 0.0331 - val_acc: 0.9889\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 56s - loss: 0.0503 - acc: 0.9857 - val_loss: 0.0296 - val_acc: 0.9894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.keras.python.keras.callbacks.History at 0x7f444d0dda90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0295599046768\n",
      "Test accuracy: 0.9894\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module tensorflow.contrib.keras.python.keras.backend in tensorflow.contrib.keras.python.keras:\n",
      "\n",
      "NAME\n",
      "    tensorflow.contrib.keras.python.keras.backend - Keras backend API.\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        Function\n",
      "    \n",
      "    class Function(builtins.object)\n",
      "     |  Runs a computation graph.\n",
      "     |  \n",
      "     |  Arguments:\n",
      "     |      inputs: Feed placeholders to the computation graph.\n",
      "     |      outputs: Output tensors to fetch.\n",
      "     |      updates: Additional update ops to be run at function call.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, inputs)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  __init__(self, inputs, outputs, updates=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    abs(x)\n",
      "        Element-wise absolute value.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    all(x, axis=None, keepdims=False)\n",
      "        Bitwise reduction (logical AND).\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            axis: axis along which to perform the reduction.\n",
      "            keepdims: whether the drop or broadcast the reduction axes.\n",
      "        \n",
      "        Returns:\n",
      "            A uint8 tensor (0s and 1s).\n",
      "    \n",
      "    any(x, axis=None, keepdims=False)\n",
      "        Bitwise reduction (logical OR).\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            axis: axis along which to perform the reduction.\n",
      "            keepdims: whether the drop or broadcast the reduction axes.\n",
      "        \n",
      "        Returns:\n",
      "            A uint8 tensor (0s and 1s).\n",
      "    \n",
      "    arange(start, stop=None, step=1, dtype='int32')\n",
      "        Creates a 1D tensor containing a sequence of integers.\n",
      "        \n",
      "        The function arguments use the same convention as\n",
      "        Theano's arange: if only one argument is provided,\n",
      "        it is in fact the \"stop\" argument.\n",
      "        \n",
      "        The default type of the returned tensor is `'int32'` to\n",
      "        match TensorFlow's default.\n",
      "        \n",
      "        Arguments:\n",
      "            start: Start value.\n",
      "            stop: Stop value.\n",
      "            step: Difference between two successive values.\n",
      "            dtype: Integer dtype to use.\n",
      "        \n",
      "        Returns:\n",
      "            An integer tensor.\n",
      "    \n",
      "    argmax(x, axis=-1)\n",
      "        Returns the index of the maximum value along an axis.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            axis: axis along which to perform the reduction.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    argmin(x, axis=-1)\n",
      "        Returns the index of the minimum value along an axis.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            axis: axis along which to perform the reduction.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    backend()\n",
      "        Publicly accessible method for determining the current backend.\n",
      "        \n",
      "        Only exists for API compatibily with multi-backend Keras.\n",
      "        \n",
      "        Returns:\n",
      "            The string \"tensorflow\".\n",
      "    \n",
      "    batch_dot(x, y, axes=None)\n",
      "        Batchwise dot product.\n",
      "        \n",
      "        `batch_dot` is used to compute dot product of `x` and `y` when\n",
      "        `x` and `y` are data in batch, i.e. in a shape of\n",
      "        `(batch_size, :)`.\n",
      "        `batch_dot` results in a tensor or variable with less dimensions\n",
      "        than the input. If the number of dimensions is reduced to 1,\n",
      "        we use `expand_dims` to make sure that ndim is at least 2.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Keras tensor or variable with `ndim >= 2`.\n",
      "            y: Keras tensor or variable with `ndim >= 2`.\n",
      "            axes: list of (or single) int with target dimensions.\n",
      "                The lengths of `axes[0]` and `axes[1]` should be the same.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor with shape equal to the concatenation of `x`'s shape\n",
      "            (less the dimension that was summed over) and `y`'s shape\n",
      "            (less the batch dimension and the dimension that was summed over).\n",
      "            If the final rank is 1, we reshape it to `(batch_size, 1)`.\n",
      "        \n",
      "        Examples:\n",
      "            Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`\n",
      "            `batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal\n",
      "            of `x.dot(y.T)`, although we never have to calculate the off-diagonal\n",
      "            elements.\n",
      "        \n",
      "            Shape inference:\n",
      "            Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.\n",
      "            If `axes` is (1, 2), to find the output shape of resultant tensor,\n",
      "                loop through each dimension in `x`'s shape and `y`'s shape:\n",
      "        \n",
      "            * `x.shape[0]` : 100 : append to output shape\n",
      "            * `x.shape[1]` : 20 : do not append to output shape,\n",
      "                dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)\n",
      "            * `y.shape[0]` : 100 : do not append to output shape,\n",
      "                always ignore first dimension of `y`\n",
      "            * `y.shape[1]` : 30 : append to output shape\n",
      "            * `y.shape[2]` : 20 : do not append to output shape,\n",
      "                dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)\n",
      "            `output_shape` = `(100, 30)`\n",
      "        \n",
      "        ```python\n",
      "            >>> x_batch = K.ones(shape=(32, 20, 1))\n",
      "            >>> y_batch = K.ones(shape=(32, 30, 20))\n",
      "            >>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])\n",
      "            >>> K.int_shape(xy_batch_dot)\n",
      "            (32, 1, 30)\n",
      "        ```\n",
      "    \n",
      "    batch_flatten(x)\n",
      "        Turn a nD tensor into a 2D tensor with same 0th dimension.\n",
      "        \n",
      "        In other words, it flattens each data samples of a batch.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    batch_get_value(tensors)\n",
      "        Returns the value of more than one tensor variable.\n",
      "        \n",
      "        Arguments:\n",
      "            tensors: list of ops to run.\n",
      "        \n",
      "        Returns:\n",
      "            A list of Numpy arrays.\n",
      "    \n",
      "    batch_normalization(x, mean, var, beta, gamma, epsilon=0.001)\n",
      "        Applies batch normalization on x given mean, var, beta and gamma.\n",
      "        \n",
      "        I.e. returns:\n",
      "        `output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta`\n",
      "        \n",
      "        Arguments:\n",
      "            x: Input tensor or variable.\n",
      "            mean: Mean of batch.\n",
      "            var: Variance of batch.\n",
      "            beta: Tensor with which to center the input.\n",
      "            gamma: Tensor by which to scale the input.\n",
      "            epsilon: Fuzz factor.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    batch_set_value(tuples)\n",
      "        Sets the values of many tensor variables at once.\n",
      "        \n",
      "        Arguments:\n",
      "            tuples: a list of tuples `(tensor, value)`.\n",
      "                `value` should be a Numpy array.\n",
      "    \n",
      "    bias_add(x, bias, data_format=None)\n",
      "        Adds a bias vector to a tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            bias: Bias tensor to add.\n",
      "            data_format: Data format for 3D, 4D or 5D tensors:\n",
      "                one of \"channels_first\", \"channels_last\".\n",
      "        \n",
      "        Returns:\n",
      "            Output tensor.\n",
      "        \n",
      "        Raises:\n",
      "            ValueError: In case of invalid `data_format` argument.\n",
      "    \n",
      "    binary_crossentropy(output, target, from_logits=False)\n",
      "        Binary crossentropy between an output tensor and a target tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            output: A tensor.\n",
      "            target: A tensor with the same shape as `output`.\n",
      "            from_logits: Whether `output` is expected to be a logits tensor.\n",
      "                By default, we consider that `output`\n",
      "                encodes a probability distribution.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    cast(x, dtype)\n",
      "        Casts a tensor to a different dtype and returns it.\n",
      "        \n",
      "        You can cast a Keras variable but it still returns a Keras tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Keras tensor (or variable).\n",
      "            dtype: String, either (`'float16'`, `'float32'`, or `'float64'`).\n",
      "        \n",
      "        Returns:\n",
      "            Keras tensor with dtype `dtype`.\n",
      "        \n",
      "        Example:\n",
      "        ```python\n",
      "            >>> from keras import backend as K\n",
      "            >>> input = K.placeholder((2, 3), dtype='float32')\n",
      "            >>> input\n",
      "            <tf.Tensor 'Placeholder_2:0' shape=(2, 3) dtype=float32>\n",
      "            # It doesn't work in-place as below.\n",
      "            >>> K.cast(input, dtype='float16')\n",
      "            <tf.Tensor 'Cast_1:0' shape=(2, 3) dtype=float16>\n",
      "            >>> input\n",
      "            <tf.Tensor 'Placeholder_2:0' shape=(2, 3) dtype=float32>\n",
      "            # you need to assign it.\n",
      "            >>> input = K.cast(input, dtype='float16')\n",
      "            >>> input\n",
      "            <tf.Tensor 'Cast_2:0' shape=(2, 3) dtype=float16>\n",
      "        ```\n",
      "    \n",
      "    cast_to_floatx(x)\n",
      "        Cast a Numpy array to the default Keras float type.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Numpy array.\n",
      "        \n",
      "        Returns:\n",
      "            The same Numpy array, cast to its new type.\n",
      "        \n",
      "        Example:\n",
      "        ```python\n",
      "            >>> from keras import backend as K\n",
      "            >>> K.floatx()\n",
      "            'float32'\n",
      "            >>> arr = numpy.array([1.0, 2.0], dtype='float64')\n",
      "            >>> arr.dtype\n",
      "            dtype('float64')\n",
      "            >>> new_arr = K.cast_to_floatx(arr)\n",
      "            >>> new_arr\n",
      "            array([ 1.,  2.], dtype=float32)\n",
      "            >>> new_arr.dtype\n",
      "            dtype('float32')\n",
      "        ```\n",
      "    \n",
      "    categorical_crossentropy(output, target, from_logits=False)\n",
      "        Categorical crossentropy between an output tensor and a target tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            output: A tensor resulting from a softmax\n",
      "                (unless `from_logits` is True, in which\n",
      "                case `output` is expected to be the logits).\n",
      "            target: A tensor of the same shape as `output`.\n",
      "            from_logits: Boolean, whether `output` is the\n",
      "                result of a softmax, or is a tensor of logits.\n",
      "        \n",
      "        Returns:\n",
      "            Output tensor.\n",
      "    \n",
      "    clear_session()\n",
      "        Destroys the current TF graph and creates a new one.\n",
      "        \n",
      "        Useful to avoid clutter from old models / layers.\n",
      "    \n",
      "    clip(x, min_value, max_value)\n",
      "        Element-wise value clipping.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            min_value: Python float or integer.\n",
      "            max_value: Python float or integer.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    concatenate(tensors, axis=-1)\n",
      "        Concatenates a list of tensors alongside the specified axis.\n",
      "        \n",
      "        Arguments:\n",
      "            tensors: list of tensors to concatenate.\n",
      "            axis: concatenation axis.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    constant(value, dtype=None, shape=None, name=None)\n",
      "    \n",
      "    conv1d(x, kernel, strides=1, padding='valid', data_format=None, dilation_rate=1)\n",
      "        1D convolution.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            kernel: kernel tensor.\n",
      "            strides: stride integer.\n",
      "            padding: string, `\"same\"`, `\"causal\"` or `\"valid\"`.\n",
      "            data_format: string, one of \"channels_last\", \"channels_first\".\n",
      "            dilation_rate: integer dilate rate.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor, result of 1D convolution.\n",
      "    \n",
      "    conv2d(x, kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))\n",
      "        2D convolution.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            kernel: kernel tensor.\n",
      "            strides: strides tuple.\n",
      "            padding: string, `\"same\"` or `\"valid\"`.\n",
      "            data_format: `\"channels_last\"` or `\"channels_first\"`.\n",
      "                Whether to use Theano or TensorFlow data format\n",
      "                for inputs/kernels/ouputs.\n",
      "            dilation_rate: tuple of 2 integers.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor, result of 2D convolution.\n",
      "        \n",
      "        Raises:\n",
      "            ValueError: if `data_format` is neither `channels_last` or\n",
      "            `channels_first`.\n",
      "    \n",
      "    conv2d_transpose(x, kernel, output_shape, strides=(1, 1), padding='valid', data_format=None)\n",
      "        2D deconvolution (i.e.\n",
      "        \n",
      "        transposed convolution).\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            kernel: kernel tensor.\n",
      "            output_shape: 1D int tensor for the output shape.\n",
      "            strides: strides tuple.\n",
      "            padding: string, `\"same\"` or `\"valid\"`.\n",
      "            data_format: `\"channels_last\"` or `\"channels_first\"`.\n",
      "                Whether to use Theano or TensorFlow data format\n",
      "                for inputs/kernels/ouputs.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor, result of transposed 2D convolution.\n",
      "        \n",
      "        Raises:\n",
      "            ValueError: if `data_format` is neither `channels_last` or\n",
      "            `channels_first`.\n",
      "    \n",
      "    conv3d(x, kernel, strides=(1, 1, 1), padding='valid', data_format=None, dilation_rate=(1, 1, 1))\n",
      "        3D convolution.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            kernel: kernel tensor.\n",
      "            strides: strides tuple.\n",
      "            padding: string, `\"same\"` or `\"valid\"`.\n",
      "            data_format: `\"channels_last\"` or `\"channels_first\"`.\n",
      "                Whether to use Theano or TensorFlow data format\n",
      "                for inputs/kernels/ouputs.\n",
      "            dilation_rate: tuple of 3 integers.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor, result of 3D convolution.\n",
      "        \n",
      "        Raises:\n",
      "            ValueError: if `data_format` is neither `channels_last` or\n",
      "            `channels_first`.\n",
      "    \n",
      "    cos(x)\n",
      "        Computes cos of x element-wise.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    count_params(x)\n",
      "        Returns the number of scalars in a Keras variable.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Keras variable.\n",
      "        \n",
      "        Returns:\n",
      "            Integer, the number of scalars in `x`.\n",
      "        \n",
      "        Example:\n",
      "        ```python\n",
      "            >>> kvar = K.zeros((2,3))\n",
      "            >>> K.count_params(kvar)\n",
      "            6\n",
      "            >>> K.eval(kvar)\n",
      "            array([[ 0.,  0.,  0.],\n",
      "                   [ 0.,  0.,  0.]], dtype=float32)\n",
      "        ```\n",
      "    \n",
      "    ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
      "        Runs CTC loss algorithm on each batch element.\n",
      "        \n",
      "        Arguments:\n",
      "            y_true: tensor `(samples, max_string_length)`\n",
      "                containing the truth labels.\n",
      "            y_pred: tensor `(samples, time_steps, num_categories)`\n",
      "                containing the prediction, or output of the softmax.\n",
      "            input_length: tensor `(samples, 1)` containing the sequence length for\n",
      "                each batch item in `y_pred`.\n",
      "            label_length: tensor `(samples, 1)` containing the sequence length for\n",
      "                each batch item in `y_true`.\n",
      "        \n",
      "        Returns:\n",
      "            Tensor with shape (samples,1) containing the\n",
      "                CTC loss of each element.\n",
      "    \n",
      "    ctc_decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1)\n",
      "        Decodes the output of a softmax.\n",
      "        \n",
      "        Can use either greedy search (also known as best path)\n",
      "        or a constrained dictionary search.\n",
      "        \n",
      "        Arguments:\n",
      "            y_pred: tensor `(samples, time_steps, num_categories)`\n",
      "                containing the prediction, or output of the softmax.\n",
      "            input_length: tensor `(samples, )` containing the sequence length for\n",
      "                each batch item in `y_pred`.\n",
      "            greedy: perform much faster best-path search if `true`.\n",
      "                This does not use a dictionary.\n",
      "            beam_width: if `greedy` is `false`: a beam search decoder will be used\n",
      "                with a beam of this width.\n",
      "            top_paths: if `greedy` is `false`,\n",
      "                how many of the most probable paths will be returned.\n",
      "        \n",
      "        Returns:\n",
      "            Tuple:\n",
      "                List: if `greedy` is `true`, returns a list of one element that\n",
      "                    contains the decoded sequence.\n",
      "                    If `false`, returns the `top_paths` most probable\n",
      "                    decoded sequences.\n",
      "                    Important: blank labels are returned as `-1`.\n",
      "                Tensor `(top_paths, )` that contains\n",
      "                    the log probability of each decoded sequence.\n",
      "    \n",
      "    ctc_label_dense_to_sparse(labels, label_lengths)\n",
      "        Converts CTC labels from dense to sparse.\n",
      "        \n",
      "        Arguments:\n",
      "            labels: dense CTC labels.\n",
      "            label_lengths: length of the labels.\n",
      "        \n",
      "        Returns:\n",
      "            A sparse tensor representation of the lablels.\n",
      "    \n",
      "    cumprod(x, axis=0)\n",
      "        Cumulative product of the values in a tensor, alongside the specified axis.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "            axis: An integer, the axis to compute the product.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor of the cumulative product of values of `x` along `axis`.\n",
      "    \n",
      "    cumsum(x, axis=0)\n",
      "        Cumulative sum of the values in a tensor, alongside the specified axis.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "            axis: An integer, the axis to compute the sum.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor of the cumulative sum of values of `x` along `axis`.\n",
      "    \n",
      "    dot(x, y)\n",
      "        Multiplies 2 tensors (and/or variables) and returns a *tensor*.\n",
      "        \n",
      "        When attempting to multiply a nD tensor\n",
      "        with a nD tensor, it reproduces the Theano behavior.\n",
      "        (e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`)\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            y: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor, dot product of `x` and `y`.\n",
      "        \n",
      "        Examples:\n",
      "        ```python\n",
      "            # dot product between tensors\n",
      "            >>> x = K.placeholder(shape=(2, 3))\n",
      "            >>> y = K.placeholder(shape=(3, 4))\n",
      "            >>> xy = K.dot(x, y)\n",
      "            >>> xy\n",
      "            <tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32>\n",
      "        ```\n",
      "        \n",
      "        ```python\n",
      "            # dot product between tensors\n",
      "            >>> x = K.placeholder(shape=(32, 28, 3))\n",
      "            >>> y = K.placeholder(shape=(3, 4))\n",
      "            >>> xy = K.dot(x, y)\n",
      "            >>> xy\n",
      "            <tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32>\n",
      "        ```\n",
      "        \n",
      "        ```python\n",
      "            # Theano-like behavior example\n",
      "            >>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)\n",
      "            >>> y = K.ones((4, 3, 5))\n",
      "            >>> xy = K.dot(x, y)\n",
      "            >>> K.int_shape(xy)\n",
      "            (2, 4, 5)\n",
      "        ```\n",
      "    \n",
      "    dropout(x, level, noise_shape=None, seed=None)\n",
      "        Sets entries in `x` to zero at random, while scaling the entire tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            x: tensor\n",
      "            level: fraction of the entries in the tensor\n",
      "                that will be set to 0.\n",
      "            noise_shape: shape for randomly generated keep/drop flags,\n",
      "                must be broadcastable to the shape of `x`\n",
      "            seed: random seed to ensure determinism.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    dtype(x)\n",
      "        Returns the dtype of a Keras tensor or variable, as a string.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            String, dtype of `x`.\n",
      "        \n",
      "        Examples:\n",
      "        ```python\n",
      "            >>> from keras import backend as K\n",
      "            >>> K.dtype(K.placeholder(shape=(2,4,5)))\n",
      "            'float32'\n",
      "            >>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float32'))\n",
      "            'float32'\n",
      "            >>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float64'))\n",
      "            'float64'\n",
      "            # Keras variable\n",
      "            >>> kvar = K.variable(np.array([[1, 2], [3, 4]]))\n",
      "            >>> K.dtype(kvar)\n",
      "            'float32_ref'\n",
      "            >>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n",
      "            >>> K.dtype(kvar)\n",
      "            'float32_ref'\n",
      "        ```\n",
      "    \n",
      "    elu(x, alpha=1.0)\n",
      "        Exponential linear unit.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tenor or variable to compute the activation function for.\n",
      "            alpha: A scalar, slope of positive section.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    epsilon()\n",
      "        Returns the value of the fuzz factor used in numeric expressions.\n",
      "        \n",
      "        Returns:\n",
      "            A float.\n",
      "        \n",
      "        Example:\n",
      "        ```python\n",
      "            >>> keras.backend.epsilon()\n",
      "            1e-08\n",
      "        ```\n",
      "    \n",
      "    equal(x, y)\n",
      "        Element-wise equality between two tensors.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            y: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A bool tensor.\n",
      "    \n",
      "    eval(x)\n",
      "        Evaluates the value of a variable.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A variable.\n",
      "        \n",
      "        Returns:\n",
      "            A Numpy array.\n",
      "        \n",
      "        Examples:\n",
      "        ```python\n",
      "            >>> from keras import backend as K\n",
      "            >>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n",
      "            >>> K.eval(kvar)\n",
      "            array([[ 1.,  2.],\n",
      "                   [ 3.,  4.]], dtype=float32)\n",
      "        ```\n",
      "    \n",
      "    exp(x)\n",
      "        Element-wise exponential.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    expand_dims(x, axis=-1)\n",
      "        Adds a 1-sized dimension at index \"dim\".\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "            axis: Position where to add a new axis.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor with expended dimensions.\n",
      "    \n",
      "    eye(size, dtype=None, name=None)\n",
      "        Instantiate an identity matrix and returns it.\n",
      "        \n",
      "        Arguments:\n",
      "            size: Integer, number of rows/columns.\n",
      "            dtype: String, data type of returned Keras variable.\n",
      "            name: String, name of returned Keras variable.\n",
      "        \n",
      "        Returns:\n",
      "            A Keras variable, an identity matrix.\n",
      "        \n",
      "        Example:\n",
      "        ```python\n",
      "            >>> from keras import backend as K\n",
      "            >>> kvar = K.eye(3)\n",
      "            >>> K.eval(kvar)\n",
      "            array([[ 1.,  0.,  0.],\n",
      "                   [ 0.,  1.,  0.],\n",
      "                   [ 0.,  0.,  1.]], dtype=float32)\n",
      "        ```\n",
      "    \n",
      "    flatten(x)\n",
      "        Flatten a tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor, reshaped into 1-D\n",
      "    \n",
      "    floatx()\n",
      "        Returns the default float type, as a string.\n",
      "        \n",
      "        E.g. 'float16', 'float32', 'float64'.\n",
      "        \n",
      "        Returns:\n",
      "            String, the current default float type.\n",
      "        \n",
      "        Example:\n",
      "        ```python\n",
      "            >>> keras.backend.floatx()\n",
      "            'float32'\n",
      "        ```\n",
      "    \n",
      "    foldl(fn, elems, initializer=None, name=None)\n",
      "        Reduce elems using fn to combine them from left to right.\n",
      "        \n",
      "        Arguments:\n",
      "            fn: Callable that will be called upon each element in elems and an\n",
      "                accumulator, for instance `lambda acc, x: acc + x`\n",
      "            elems: tensor\n",
      "            initializer: The first value used (`elems[0]` in case of None)\n",
      "            name: A string name for the foldl node in the graph\n",
      "        \n",
      "        Returns:\n",
      "            Tensor with same type and shape as `initializer`.\n",
      "    \n",
      "    foldr(fn, elems, initializer=None, name=None)\n",
      "        Reduce elems using fn to combine them from right to left.\n",
      "        \n",
      "        Arguments:\n",
      "            fn: Callable that will be called upon each element in elems and an\n",
      "                accumulator, for instance `lambda acc, x: acc + x`\n",
      "            elems: tensor\n",
      "            initializer: The first value used (`elems[-1]` in case of None)\n",
      "            name: A string name for the foldr node in the graph\n",
      "        \n",
      "        Returns:\n",
      "            Same type and shape as initializer\n",
      "    \n",
      "    function(inputs, outputs, updates=None, **kwargs)\n",
      "        Instantiates a Keras function.\n",
      "        \n",
      "        Arguments:\n",
      "            inputs: List of placeholder tensors.\n",
      "            outputs: List of output tensors.\n",
      "            updates: List of update ops.\n",
      "            **kwargs: Not used with TensorFlow.\n",
      "        \n",
      "        Returns:\n",
      "            Output values as Numpy arrays.\n",
      "    \n",
      "    gather(reference, indices)\n",
      "        Retrieves the elements of indices `indices` in the tensor `reference`.\n",
      "        \n",
      "        Arguments:\n",
      "            reference: A tensor.\n",
      "            indices: An integer tensor of indices.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor of same type as `reference`.\n",
      "    \n",
      "    get_session()\n",
      "        Returns the TF session to be used by the backend.\n",
      "        \n",
      "        If a default TensorFlow session is available, we will return it.\n",
      "        \n",
      "        Else, we will return the global Keras session.\n",
      "        \n",
      "        If no global Keras session exists at this point:\n",
      "        we will create a new global session.\n",
      "        \n",
      "        Note that you can manually set the global session\n",
      "        via `K.set_session(sess)`.\n",
      "        \n",
      "        Returns:\n",
      "            A TensorFlow session.\n",
      "    \n",
      "    get_uid(prefix='')\n",
      "        Associates a string prefix with an integer counter in a TensorFlow graph.\n",
      "        \n",
      "        Arguments:\n",
      "          prefix: String prefix to index.\n",
      "        \n",
      "        Returns:\n",
      "          Unique integer ID.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```\n",
      "          >>> get_uid('dense')\n",
      "          1\n",
      "          >>> get_uid('dense')\n",
      "          2\n",
      "        ```\n",
      "    \n",
      "    get_value(x)\n",
      "        Returns the value of a variable.\n",
      "        \n",
      "        Arguments:\n",
      "            x: input variable.\n",
      "        \n",
      "        Returns:\n",
      "            A Numpy array.\n",
      "    \n",
      "    gradients(loss, variables)\n",
      "        Returns the gradients of `variables` w.r.t. `loss`.\n",
      "        \n",
      "        Arguments:\n",
      "            loss: Scalar tensor to minimize.\n",
      "            variables: List of variables.\n",
      "        \n",
      "        Returns:\n",
      "            A gradients tensor.\n",
      "    \n",
      "    greater(x, y)\n",
      "        Element-wise truth value of (x > y).\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            y: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A bool tensor.\n",
      "    \n",
      "    greater_equal(x, y)\n",
      "        Element-wise truth value of (x >= y).\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            y: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A bool tensor.\n",
      "    \n",
      "    hard_sigmoid(x)\n",
      "        Segment-wise linear approximation of sigmoid.\n",
      "        \n",
      "        Faster than sigmoid.\n",
      "        Returns `0.` if `x < -2.5`, `1.` if `x > 2.5`.\n",
      "        In `-2.5 <= x <= 2.5`, returns `0.2 * x + 0.5`.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    image_data_format()\n",
      "        Returns the default image data format convention.\n",
      "        \n",
      "        Returns:\n",
      "            A string, either `'channels_first'` or `'channels_last'`\n",
      "        \n",
      "        Example:\n",
      "        ```python\n",
      "            >>> keras.backend.image_data_format()\n",
      "            'channels_first'\n",
      "        ```\n",
      "    \n",
      "    in_test_phase(x, alt, training=None)\n",
      "        Selects `x` in test phase, and `alt` otherwise.\n",
      "        \n",
      "        Note that `alt` should have the *same shape* as `x`.\n",
      "        \n",
      "        Arguments:\n",
      "            x: What to return in test phase\n",
      "                (tensor or callable that returns a tensor).\n",
      "            alt: What to return otherwise\n",
      "                (tensor or callable that returns a tensor).\n",
      "            training: Optional scalar tensor\n",
      "                (or Python boolean, or Python integer)\n",
      "                specifing the learning phase.\n",
      "        \n",
      "        Returns:\n",
      "            Either `x` or `alt` based on `K.learning_phase`.\n",
      "    \n",
      "    in_top_k(predictions, targets, k)\n",
      "        Returns whether the `targets` are in the top `k` `predictions`.\n",
      "        \n",
      "        Arguments:\n",
      "            predictions: A tensor of shape `(batch_size, classes)` and type `float32`.\n",
      "            targets: A 1D tensor of length `batch_size` and type `int32` or `int64`.\n",
      "            k: An `int`, number of top elements to consider.\n",
      "        \n",
      "        Returns:\n",
      "            A 1D tensor of length `batch_size` and type `bool`.\n",
      "            `output[i]` is `True` if `predictions[i, targets[i]]` is within top-`k`\n",
      "            values of `predictions[i]`.\n",
      "    \n",
      "    in_train_phase(x, alt, training=None)\n",
      "        Selects `x` in train phase, and `alt` otherwise.\n",
      "        \n",
      "        Note that `alt` should have the *same shape* as `x`.\n",
      "        \n",
      "        Arguments:\n",
      "            x: What to return in train phase\n",
      "                (tensor or callable that returns a tensor).\n",
      "            alt: What to return otherwise\n",
      "                (tensor or callable that returns a tensor).\n",
      "            training: Optional scalar tensor\n",
      "                (or Python boolean, or Python integer)\n",
      "                specifing the learning phase.\n",
      "        \n",
      "        Returns:\n",
      "            Either `x` or `alt` based on the `training` flag.\n",
      "            the `training` flag defaults to `K.learning_phase()`.\n",
      "    \n",
      "    int_shape(x)\n",
      "        Returns the shape tensor or variable as a tuple of int or None entries.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tuple of integers (or None entries).\n",
      "        \n",
      "        Examples:\n",
      "        ```python\n",
      "            >>> from keras import backend as K\n",
      "            >>> input = K.placeholder(shape=(2, 4, 5))\n",
      "            >>> K.int_shape(input)\n",
      "            (2, 4, 5)\n",
      "            >>> val = np.array([[1, 2], [3, 4]])\n",
      "            >>> kvar = K.variable(value=val)\n",
      "            >>> K.int_shape(kvar)\n",
      "            (2, 2)\n",
      "        ```\n",
      "    \n",
      "    is_sparse(tensor)\n",
      "        Returns whether a tensor is a sparse tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            tensor: A tensor instance.\n",
      "        \n",
      "        Returns:\n",
      "            A boolean.\n",
      "        \n",
      "        Example:\n",
      "        ```python\n",
      "            >>> from keras import backend as K\n",
      "            >>> a = K.placeholder((2, 2), sparse=False)\n",
      "            >>> print(K.is_sparse(a))\n",
      "            False\n",
      "            >>> b = K.placeholder((2, 2), sparse=True)\n",
      "            >>> print(K.is_sparse(b))\n",
      "            True\n",
      "        ```\n",
      "    \n",
      "    l2_normalize(x, axis)\n",
      "        Normalizes a tensor wrt the L2 norm alongside the specified axis.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            axis: axis along which to perform normalization.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    learning_phase()\n",
      "        Returns the learning phase flag.\n",
      "        \n",
      "        The learning phase flag is a bool tensor (0 = test, 1 = train)\n",
      "        to be passed as input to any Keras function\n",
      "        that uses a different behavior at train time and test time.\n",
      "        \n",
      "        Returns:\n",
      "            Learning phase (scalar integer tensor or Python integer).\n",
      "    \n",
      "    less(x, y)\n",
      "        Element-wise truth value of (x < y).\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            y: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A bool tensor.\n",
      "    \n",
      "    less_equal(x, y)\n",
      "        Element-wise truth value of (x <= y).\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            y: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A bool tensor.\n",
      "    \n",
      "    log(x)\n",
      "        Element-wise log.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    manual_variable_initialization(value)\n",
      "        Sets the manual variable initialization flag.\n",
      "        \n",
      "        This boolean flag determines whether\n",
      "        variables should be initialized\n",
      "        as they are instantiated (default), or if\n",
      "        the user should handle the initialization\n",
      "        (e.g. via `tf.initialize_all_variables()`).\n",
      "        \n",
      "        Arguments:\n",
      "            value: Python boolean.\n",
      "    \n",
      "    map_fn(fn, elems, name=None, dtype=None)\n",
      "        Map the function fn over the elements elems and return the outputs.\n",
      "        \n",
      "        Arguments:\n",
      "            fn: Callable that will be called upon each element in elems\n",
      "            elems: tensor\n",
      "            name: A string name for the map node in the graph\n",
      "            dtype: Output data type.\n",
      "        \n",
      "        Returns:\n",
      "            Tensor with dtype `dtype`.\n",
      "    \n",
      "    max(x, axis=None, keepdims=False)\n",
      "        Maximum value in a tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "            axis: An integer, the axis to find maximum values.\n",
      "            keepdims: A boolean, whether to keep the dimensions or not.\n",
      "                If `keepdims` is `False`, the rank of the tensor is reduced\n",
      "                by 1. If `keepdims` is `True`,\n",
      "                the reduced dimension is retained with length 1.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor with maximum values of `x`.\n",
      "    \n",
      "    maximum(x, y)\n",
      "        Element-wise maximum of two tensors.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            y: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    mean(x, axis=None, keepdims=False)\n",
      "        Mean of a tensor, alongside the specified axis.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "            axis: A list of integer. Axes to compute the mean.\n",
      "            keepdims: A boolean, whether to keep the dimensions or not.\n",
      "                If `keepdims` is `False`, the rank of the tensor is reduced\n",
      "                by 1 for each entry in `axis`. If `keep_dims` is `True`,\n",
      "                the reduced dimensions are retained with length 1.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor with the mean of elements of `x`.\n",
      "    \n",
      "    min(x, axis=None, keepdims=False)\n",
      "        Minimum value in a tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "            axis: An integer, the axis to find minimum values.\n",
      "            keepdims: A boolean, whether to keep the dimensions or not.\n",
      "                If `keepdims` is `False`, the rank of the tensor is reduced\n",
      "                by 1. If `keepdims` is `True`,\n",
      "                the reduced dimension is retained with length 1.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor with miminum values of `x`.\n",
      "    \n",
      "    minimum(x, y)\n",
      "        Element-wise minimum of two tensors.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            y: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    moving_average_update(x, value, momentum)\n",
      "    \n",
      "    ndim(x)\n",
      "        Returns the number of axes in a tensor, as an integer.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            Integer (scalar), number of axes.\n",
      "        \n",
      "        Examples:\n",
      "        ```python\n",
      "            >>> from keras import backend as K\n",
      "            >>> input = K.placeholder(shape=(2, 4, 5))\n",
      "            >>> val = np.array([[1, 2], [3, 4]])\n",
      "            >>> kvar = K.variable(value=val)\n",
      "            >>> K.ndim(input)\n",
      "            3\n",
      "            >>> K.ndim(kvar)\n",
      "            2\n",
      "        ```\n",
      "    \n",
      "    normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)\n",
      "        Computes mean and std for batch then apply batch_normalization on batch.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Input tensor or variable.\n",
      "            gamma: Tensor by which to scale the input.\n",
      "            beta: Tensor with which to center the input.\n",
      "            reduction_axes: iterable of integers,\n",
      "                axes over which to normalize.\n",
      "            epsilon: Fuzz factor.\n",
      "        \n",
      "        Returns:\n",
      "            A tuple length of 3, `(normalized_tensor, mean, variance)`.\n",
      "    \n",
      "    not_equal(x, y)\n",
      "        Element-wise inequality between two tensors.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            y: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A bool tensor.\n",
      "    \n",
      "    one_hot(indices, num_classes)\n",
      "        Computes the one-hot representation of an integer tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            indices: nD integer tensor of shape\n",
      "                `(batch_size, dim1, dim2, ... dim(n-1))`\n",
      "            num_classes: Integer, number of classes to consider.\n",
      "        \n",
      "        Returns:\n",
      "            (n + 1)D one hot representation of the input\n",
      "            with shape `(batch_size, dim1, dim2, ... dim(n-1), num_classes)`\n",
      "        \n",
      "        Returns:\n",
      "            The one-hot tensor.\n",
      "    \n",
      "    ones(shape, dtype=None, name=None)\n",
      "        Instantiates an all-ones tensor variable and returns it.\n",
      "        \n",
      "        Arguments:\n",
      "            shape: Tuple of integers, shape of returned Keras variable.\n",
      "            dtype: String, data type of returned Keras variable.\n",
      "            name: String, name of returned Keras variable.\n",
      "        \n",
      "        Returns:\n",
      "            A Keras variable, filled with `1.0`.\n",
      "        \n",
      "        Example:\n",
      "        ```python\n",
      "            >>> from keras import backend as K\n",
      "            >>> kvar = K.ones((3,4))\n",
      "            >>> K.eval(kvar)\n",
      "            array([[ 1.,  1.,  1.,  1.],\n",
      "                   [ 1.,  1.,  1.,  1.],\n",
      "                   [ 1.,  1.,  1.,  1.]], dtype=float32)\n",
      "        ```\n",
      "    \n",
      "    ones_like(x, dtype=None, name=None)\n",
      "        Instantiates an all-ones variable of the same shape as another tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Keras variable or tensor.\n",
      "            dtype: String, dtype of returned Keras variable.\n",
      "                 None uses the dtype of x.\n",
      "            name: String, name for the variable to create.\n",
      "        \n",
      "        Returns:\n",
      "            A Keras variable with the shape of x filled with ones.\n",
      "        \n",
      "        Example:\n",
      "        ```python\n",
      "            >>> from keras import backend as K\n",
      "            >>> kvar = K.variable(np.random.random((2,3)))\n",
      "            >>> kvar_ones = K.ones_like(kvar)\n",
      "            >>> K.eval(kvar_ones)\n",
      "            array([[ 1.,  1.,  1.],\n",
      "                   [ 1.,  1.,  1.]], dtype=float32)\n",
      "        ```\n",
      "    \n",
      "    permute_dimensions(x, pattern)\n",
      "        Permutes axes in a tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            pattern: A tuple of\n",
      "                dimension indices, e.g. `(0, 2, 1)`.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None)\n",
      "        Instantiates a placeholder tensor and returns it.\n",
      "        \n",
      "        Arguments:\n",
      "            shape: Shape of the placeholder\n",
      "                (integer tuple, may include `None` entries).\n",
      "            ndim: Number of axes of the tensor.\n",
      "                At least one of {`shape`, `ndim`} must be specified.\n",
      "                If both are specified, `shape` is used.\n",
      "            dtype: Placeholder type.\n",
      "            sparse: Boolean, whether the placeholder should have a sparse type.\n",
      "            name: Optional name string for the placeholder.\n",
      "        \n",
      "        Returns:\n",
      "            Tensor instance (with Keras metadata included).\n",
      "        \n",
      "        Examples:\n",
      "        ```python\n",
      "            >>> from keras import backend as K\n",
      "            >>> input_ph = K.placeholder(shape=(2, 4, 5))\n",
      "            >>> input_ph\n",
      "            <tf.Tensor 'Placeholder_4:0' shape=(2, 4, 5) dtype=float32>\n",
      "        ```\n",
      "    \n",
      "    pool2d(x, pool_size, strides=(1, 1), padding='valid', data_format=None, pool_mode='max')\n",
      "        2D Pooling.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            pool_size: tuple of 2 integers.\n",
      "            strides: tuple of 2 integers.\n",
      "            padding: one of `\"valid\"`, `\"same\"`.\n",
      "            data_format: one of `\"channels_first\"`, `\"channels_last\"`.\n",
      "            pool_mode: one of `\"max\"`, `\"avg\"`.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor, result of 2D pooling.\n",
      "        \n",
      "        Raises:\n",
      "            ValueError: if `data_format` is neither `channels_last` or\n",
      "            `channels_first`.\n",
      "            ValueError: if `pool_mode` is neither `max` or `avg`.\n",
      "    \n",
      "    pool3d(x, pool_size, strides=(1, 1, 1), padding='valid', data_format=None, pool_mode='max')\n",
      "        3D Pooling.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            pool_size: tuple of 3 integers.\n",
      "            strides: tuple of 3 integers.\n",
      "            padding: one of `\"valid\"`, `\"same\"`.\n",
      "            data_format: one of `\"channels_first\"`, `\"channels_last\"`.\n",
      "            pool_mode: one of `\"max\"`, `\"avg\"`.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor, result of 3D pooling.\n",
      "        \n",
      "        Raises:\n",
      "            ValueError: if `data_format` is neither\n",
      "                `channels_last` or `channels_first`.\n",
      "            ValueError: if `pool_mode` is neither `max` or `avg`.\n",
      "    \n",
      "    pow(x, a)\n",
      "        Element-wise exponentiation.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            a: Python integer.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    print_tensor(x, message='')\n",
      "        Prints `message` and the tensor value when evaluated.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor to print.\n",
      "            message: Message to print jointly with the tensor.\n",
      "        \n",
      "        Returns:\n",
      "            The same tensor `x`, unchanged.\n",
      "    \n",
      "    prod(x, axis=None, keepdims=False)\n",
      "        Multiplies the values in a tensor, alongside the specified axis.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "            axis: An integer, the axis to compute the product.\n",
      "            keepdims: A boolean, whether to keep the dimensions or not.\n",
      "                If `keepdims` is `False`, the rank of the tensor is reduced\n",
      "                by 1. If `keepdims` is `True`,\n",
      "                the reduced dimension is retained with length 1.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor with the product of elements of `x`.\n",
      "    \n",
      "    py_all = all(iterable, /)\n",
      "        Return True if bool(x) is True for all values x in the iterable.\n",
      "        \n",
      "        If the iterable is empty, return True.\n",
      "    \n",
      "    py_sum = sum(iterable, start=0, /)\n",
      "        Return the sum of a 'start' value (default: 0) plus an iterable of numbers\n",
      "        \n",
      "        When the iterable is empty, return the start value.\n",
      "        This function is intended specifically for use with numeric values and may\n",
      "        reject non-numeric types.\n",
      "    \n",
      "    random_binomial(shape, p=0.0, dtype=None, seed=None)\n",
      "        Returns a tensor with random binomial distribution of values.\n",
      "        \n",
      "        Arguments:\n",
      "            shape: A tuple of integers, the shape of tensor to create.\n",
      "            p: A float, `0. <= p <= 1`, probability of binomial distribution.\n",
      "            dtype: String, dtype of returned tensor.\n",
      "            seed: Integer, random seed.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None)\n",
      "        Returns a tensor with normal distribution of values.\n",
      "        \n",
      "        Arguments:\n",
      "            shape: A tuple of integers, the shape of tensor to create.\n",
      "            mean: A float, mean of the normal distribution to draw samples.\n",
      "            stddev: A float, standard deviation of the normal distribution\n",
      "                to draw samples.\n",
      "            dtype: String, dtype of returned tensor.\n",
      "            seed: Integer, random seed.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    random_normal_variable(shape, mean, scale, dtype=None, name=None, seed=None)\n",
      "        Instantiates a variable with values drawn from a normal distribution.\n",
      "        \n",
      "        Arguments:\n",
      "            shape: Tuple of integers, shape of returned Keras variable.\n",
      "            mean: Float, mean of the normal distribution.\n",
      "            scale: Float, standard deviation of the normal distribution.\n",
      "            dtype: String, dtype of returned Keras variable.\n",
      "            name: String, name of returned Keras variable.\n",
      "            seed: Integer, random seed.\n",
      "        \n",
      "        Returns:\n",
      "            A Keras variable, filled with drawn samples.\n",
      "        \n",
      "        Example:\n",
      "        ```python\n",
      "            # TensorFlow example\n",
      "            >>> kvar = K.random_normal_variable((2,3), 0, 1)\n",
      "            >>> kvar\n",
      "            <tensorflow.python.ops.variables.Variable object at 0x10ab12dd0>\n",
      "            >>> K.eval(kvar)\n",
      "            array([[ 1.19591331,  0.68685907, -0.63814116],\n",
      "                   [ 0.92629528,  0.28055015,  1.70484698]], dtype=float32)\n",
      "        ```\n",
      "    \n",
      "    random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None)\n",
      "        Returns a tensor with uniform distribution of values.\n",
      "        \n",
      "        Arguments:\n",
      "            shape: A tuple of integers, the shape of tensor to create.\n",
      "            minval: A float, lower boundary of the uniform distribution\n",
      "                to draw samples.\n",
      "            maxval: A float, upper boundary of the uniform distribution\n",
      "                to draw samples.\n",
      "            dtype: String, dtype of returned tensor.\n",
      "            seed: Integer, random seed.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    random_uniform_variable(shape, low, high, dtype=None, name=None, seed=None)\n",
      "        Instantiates a variable with values drawn from a uniform distribution.\n",
      "        \n",
      "        Arguments:\n",
      "            shape: Tuple of integers, shape of returned Keras variable.\n",
      "            low: Float, lower boundary of the output interval.\n",
      "            high: Float, upper boundary of the output interval.\n",
      "            dtype: String, dtype of returned Keras variable.\n",
      "            name: String, name of returned Keras variable.\n",
      "            seed: Integer, random seed.\n",
      "        \n",
      "        Returns:\n",
      "            A Keras variable, filled with drawn samples.\n",
      "        \n",
      "        Example:\n",
      "        ```python\n",
      "            # TensorFlow example\n",
      "            >>> kvar = K.random_uniform_variable((2,3), 0, 1)\n",
      "            >>> kvar\n",
      "            <tensorflow.python.ops.variables.Variable object at 0x10ab40b10>\n",
      "            >>> K.eval(kvar)\n",
      "            array([[ 0.10940075,  0.10047495,  0.476143  ],\n",
      "                   [ 0.66137183,  0.00869417,  0.89220798]], dtype=float32)\n",
      "        ```\n",
      "    \n",
      "    relu(x, alpha=0.0, max_value=None)\n",
      "        Rectified linear unit.\n",
      "        \n",
      "        With default values, it returns element-wise `max(x, 0)`.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "            alpha: A scalar, slope of negative section (default=`0.`).\n",
      "            max_value: Saturation threshold.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    repeat(x, n)\n",
      "        Repeats a 2D tensor.\n",
      "        \n",
      "        if `x` has shape (samples, dim) and `n` is `2`,\n",
      "        the output will have shape `(samples, 2, dim)`.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            n: Python integer, number of times to repeat.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    repeat_elements(x, rep, axis)\n",
      "        Repeats the elements of a tensor along an axis, like `np.repeat`.\n",
      "        \n",
      "        If `x` has shape `(s1, s2, s3)` and `axis` is `1`, the output\n",
      "        will have shape `(s1, s2 * rep, s3)`.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            rep: Python integer, number of times to repeat.\n",
      "            axis: Axis along which to repeat.\n",
      "        \n",
      "        Raises:\n",
      "            ValueError: In case `x.shape[axis]` is undefined.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    reset_uids()\n",
      "    \n",
      "    reshape(x, shape)\n",
      "        Reshapes a tensor to the specified shape.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            shape: Target shape tuple.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    resize_images(x, height_factor, width_factor, data_format)\n",
      "        Resizes the images contained in a 4D tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable to resize.\n",
      "            height_factor: Positive integer.\n",
      "            width_factor: Positive integer.\n",
      "            data_format: One of `\"channels_first\"`, `\"channels_last\"`.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "        \n",
      "        Raises:\n",
      "            ValueError: if `data_format` is neither\n",
      "                `channels_last` or `channels_first`.\n",
      "    \n",
      "    resize_volumes(x, depth_factor, height_factor, width_factor, data_format)\n",
      "        Resizes the volume contained in a 5D tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable to resize.\n",
      "            depth_factor: Positive integer.\n",
      "            height_factor: Positive integer.\n",
      "            width_factor: Positive integer.\n",
      "            data_format: One of `\"channels_first\"`, `\"channels_last\"`.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "        \n",
      "        Raises:\n",
      "            ValueError: if `data_format` is neither\n",
      "                `channels_last` or `channels_first`.\n",
      "    \n",
      "    reverse(x, axes)\n",
      "        Reverse a tensor along the specified axes.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor to reverse.\n",
      "            axes: Integer or iterable of integers.\n",
      "                Axes to reverse.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    rnn(step_function, inputs, initial_states, go_backwards=False, mask=None, constants=None, unroll=False)\n",
      "        Iterates over the time dimension of a tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            step_function: RNN step function.\n",
      "                Parameters;\n",
      "                    input; tensor with shape `(samples, ...)` (no time dimension),\n",
      "                        representing input for the batch of samples at a certain\n",
      "                        time step.\n",
      "                    states; list of tensors.\n",
      "                Returns;\n",
      "                    output; tensor with shape `(samples, output_dim)`\n",
      "                        (no time dimension).\n",
      "                    new_states; list of tensors, same length and shapes\n",
      "                        as 'states'. The first state in the list must be the\n",
      "                        output tensor at the previous timestep.\n",
      "            inputs: tensor of temporal data of shape `(samples, time, ...)`\n",
      "                (at least 3D).\n",
      "            initial_states: tensor with shape (samples, output_dim)\n",
      "                (no time dimension),\n",
      "                containing the initial values for the states used in\n",
      "                the step function.\n",
      "            go_backwards: boolean. If True, do the iteration over the time\n",
      "                dimension in reverse order and return the reversed sequence.\n",
      "            mask: binary tensor with shape `(samples, time, 1)`,\n",
      "                with a zero for every element that is masked.\n",
      "            constants: a list of constant values passed at each step.\n",
      "            unroll: whether to unroll the RNN or to use a symbolic loop\n",
      "                (`while_loop` or `scan` depending on backend).\n",
      "        \n",
      "        Returns:\n",
      "            A tuple, `(last_output, outputs, new_states)`.\n",
      "                last_output: the latest output of the rnn, of shape `(samples, ...)`\n",
      "                outputs: tensor with shape `(samples, time, ...)` where each\n",
      "                    entry `outputs[s, t]` is the output of the step function\n",
      "                    at time `t` for sample `s`.\n",
      "                new_states: list of tensors, latest states returned by\n",
      "                    the step function, of shape `(samples, ...)`.\n",
      "        \n",
      "        Raises:\n",
      "            ValueError: if input dimension is less than 3.\n",
      "            ValueError: if `unroll` is `True` but input timestep is not a fixed\n",
      "            number.\n",
      "            ValueError: if `mask` is provided (not `None`) but states is not provided\n",
      "                (`len(states)` == 0).\n",
      "    \n",
      "    round(x)\n",
      "        Element-wise rounding to the closest integer.\n",
      "        \n",
      "        In case of tie, the rounding mode used is \"half to even\".\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))\n",
      "        2D convolution with separable filters.\n",
      "        \n",
      "        Arguments:\n",
      "            x: input tensor\n",
      "            depthwise_kernel: convolution kernel for the depthwise convolution.\n",
      "            pointwise_kernel: kernel for the 1x1 convolution.\n",
      "            strides: strides tuple (length 2).\n",
      "            padding: padding mode, \"valid\" or \"same\".\n",
      "            data_format: data format, \"channels_first\" or \"channels_last\".\n",
      "            dilation_rate: tuple of integers,\n",
      "                dilation rates for the separable convolution.\n",
      "        \n",
      "        Returns:\n",
      "            Output tensor.\n",
      "        \n",
      "        Raises:\n",
      "            ValueError: if `data_format` is neither `channels_last` or\n",
      "            `channels_first`.\n",
      "    \n",
      "    set_epsilon(value)\n",
      "        Sets the value of the fuzz factor used in numeric expressions.\n",
      "        \n",
      "        Arguments:\n",
      "            value: float. New value of epsilon.\n",
      "        \n",
      "        Example:\n",
      "        ```python\n",
      "            >>> from keras import backend as K\n",
      "            >>> K.epsilon()\n",
      "            1e-08\n",
      "            >>> K.set_epsilon(1e-05)\n",
      "            >>> K.epsilon()\n",
      "            1e-05\n",
      "        ```\n",
      "    \n",
      "    set_floatx(value)\n",
      "        Sets the default float type.\n",
      "        \n",
      "        Arguments:\n",
      "            value: String; 'float16', 'float32', or 'float64'.\n",
      "        \n",
      "        Example:\n",
      "        ```python\n",
      "            >>> from keras import backend as K\n",
      "            >>> K.floatx()\n",
      "            'float32'\n",
      "            >>> K.set_floatx('float16')\n",
      "            >>> K.floatx()\n",
      "            'float16'\n",
      "        ```\n",
      "        \n",
      "        Raises:\n",
      "            ValueError: In case of invalid value.\n",
      "    \n",
      "    set_image_data_format(data_format)\n",
      "        Sets the value of the image data format convention.\n",
      "        \n",
      "        Arguments:\n",
      "            data_format: string. `'channels_first'` or `'channels_last'`.\n",
      "        \n",
      "        Example:\n",
      "        ```python\n",
      "            >>> from keras import backend as K\n",
      "            >>> K.image_data_format()\n",
      "            'channels_first'\n",
      "            >>> K.set_image_data_format('channels_last')\n",
      "            >>> K.image_data_format()\n",
      "            'channels_last'\n",
      "        ```\n",
      "        \n",
      "        Raises:\n",
      "            ValueError: In case of invalid `data_format` value.\n",
      "    \n",
      "    set_learning_phase(value)\n",
      "        Sets the learning phase to a fixed value.\n",
      "        \n",
      "        Arguments:\n",
      "            value: Learning phase value, either 0 or 1 (integers).\n",
      "        \n",
      "        Raises:\n",
      "            ValueError: if `value` is neither `0` nor `1`.\n",
      "    \n",
      "    set_session(session)\n",
      "        Sets the global TensorFlow session.\n",
      "        \n",
      "        Arguments:\n",
      "            session: A TF Session.\n",
      "    \n",
      "    set_value(x, value)\n",
      "        Sets the value of a variable, from a Numpy array.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor to set to a new value.\n",
      "            value: Value to set the tensor to, as a Numpy array\n",
      "                (of the same shape).\n",
      "    \n",
      "    shape(x)\n",
      "        Returns the symbolic shape of a tensor or variable.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A symbolic shape (which is itself a tensor).\n",
      "        \n",
      "        Examples:\n",
      "        ```\n",
      "            # TensorFlow example\n",
      "            >>> from keras import backend as K\n",
      "            >>> tf_session = K.get_session()\n",
      "            >>> val = np.array([[1, 2], [3, 4]])\n",
      "            >>> kvar = K.variable(value=val)\n",
      "            >>> input = keras.backend.placeholder(shape=(2, 4, 5))\n",
      "            >>> K.shape(kvar)\n",
      "            <tf.Tensor 'Shape_8:0' shape=(2,) dtype=int32>\n",
      "            >>> K.shape(input)\n",
      "            <tf.Tensor 'Shape_9:0' shape=(3,) dtype=int32>\n",
      "            # To get integer shape (Instead, you can use K.int_shape(x))\n",
      "            >>> K.shape(kvar).eval(session=tf_session)\n",
      "            array([2, 2], dtype=int32)\n",
      "            >>> K.shape(input).eval(session=tf_session)\n",
      "            array([2, 4, 5], dtype=int32)\n",
      "        ```\n",
      "    \n",
      "    sigmoid(x)\n",
      "        Element-wise sigmoid.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    sign(x)\n",
      "        Element-wise sign.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    sin(x)\n",
      "        Computes sin of x element-wise.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    softmax(x)\n",
      "        Softmax of a tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    softplus(x)\n",
      "        Softplus of a tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    softsign(x)\n",
      "        Softsign of a tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    sparse_categorical_crossentropy(output, target, from_logits=False)\n",
      "        Categorical crossentropy with integer targets.\n",
      "        \n",
      "        Arguments:\n",
      "            output: A tensor resulting from a softmax\n",
      "                (unless `from_logits` is True, in which\n",
      "                case `output` is expected to be the logits).\n",
      "            target: An integer tensor.\n",
      "            from_logits: Boolean, whether `output` is the\n",
      "                result of a softmax, or is a tensor of logits.\n",
      "        \n",
      "        Returns:\n",
      "            Output tensor.\n",
      "    \n",
      "    spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None)\n",
      "        Pads the 2nd and 3rd dimensions of a 4D tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            padding: Tuple of 2 tuples, padding pattern.\n",
      "            data_format: One of `channels_last` or `channels_first`.\n",
      "        \n",
      "        Returns:\n",
      "            A padded 4D tensor.\n",
      "        \n",
      "        Raises:\n",
      "            ValueError: if `data_format` is neither\n",
      "                `channels_last` or `channels_first`.\n",
      "    \n",
      "    spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None)\n",
      "        Pads 5D tensor with zeros along the depth, height, width dimensions.\n",
      "        \n",
      "        Pads these dimensions with respectively\n",
      "        \"padding[0]\", \"padding[1]\" and \"padding[2]\" zeros left and right.\n",
      "        \n",
      "        For 'channels_last' data_format,\n",
      "        the 2nd, 3rd and 4th dimension will be padded.\n",
      "        For 'channels_first' data_format,\n",
      "        the 3rd, 4th and 5th dimension will be padded.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            padding: Tuple of 3 tuples, padding pattern.\n",
      "            data_format: One of `channels_last` or `channels_first`.\n",
      "        \n",
      "        Returns:\n",
      "            A padded 5D tensor.\n",
      "        \n",
      "        Raises:\n",
      "            ValueError: if `data_format` is neither\n",
      "                `channels_last` or `channels_first`.\n",
      "    \n",
      "    sqrt(x)\n",
      "        Element-wise square root.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    square(x)\n",
      "        Element-wise square.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    squeeze(x, axis)\n",
      "        Removes a 1-dimension from the tensor at index \"axis\".\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "            axis: Axis to drop.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor with the same data as `x` but reduced dimensions.\n",
      "    \n",
      "    stack(x, axis=0)\n",
      "        Stacks a list of rank `R` tensors into a rank `R+1` tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            x: List of tensors.\n",
      "            axis: Axis along which to perform stacking.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    std(x, axis=None, keepdims=False)\n",
      "        Standard deviation of a tensor, alongside the specified axis.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "            axis: An integer, the axis to compute the standard deviation.\n",
      "            keepdims: A boolean, whether to keep the dimensions or not.\n",
      "                If `keepdims` is `False`, the rank of the tensor is reduced\n",
      "                by 1. If `keepdims` is `True`,\n",
      "                the reduced dimension is retained with length 1.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor with the standard deviation of elements of `x`.\n",
      "    \n",
      "    stop_gradient(variables)\n",
      "        Returns `variables` but with zero gradient w.r.t. every other variable.\n",
      "        \n",
      "        Arguments:\n",
      "            variables: List of variables.\n",
      "        \n",
      "        Returns:\n",
      "            The same list of variables.\n",
      "    \n",
      "    sum(x, axis=None, keepdims=False)\n",
      "        Sum of the values in a tensor, alongside the specified axis.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "            axis: An integer, the axis to sum over.\n",
      "            keepdims: A boolean, whether to keep the dimensions or not.\n",
      "                If `keepdims` is `False`, the rank of the tensor is reduced\n",
      "                by 1. If `keepdims` is `True`,\n",
      "                the reduced dimension is retained with length 1.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor with sum of `x`.\n",
      "    \n",
      "    switch(condition, then_expression, else_expression)\n",
      "        Switches between two operations depending on a scalar value.\n",
      "        \n",
      "        Note that both `then_expression` and `else_expression`\n",
      "        should be symbolic tensors of the *same shape*.\n",
      "        \n",
      "        Arguments:\n",
      "            condition: scalar tensor (`int` or `bool`).\n",
      "            then_expression: either a tensor, or a callable that returns a tensor.\n",
      "            else_expression: either a tensor, or a callable that returns a tensor.\n",
      "        \n",
      "        Returns:\n",
      "            The selected tensor.\n",
      "    \n",
      "    tanh(x)\n",
      "        Element-wise tanh.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    temporal_padding(x, padding=(1, 1))\n",
      "        Pads the middle dimension of a 3D tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "            padding: Tuple of 2 integers, how many zeros to\n",
      "                add at the start and end of dim 1.\n",
      "        \n",
      "        Returns:\n",
      "            A padded 3D tensor.\n",
      "    \n",
      "    tile(x, n)\n",
      "        Creates a tensor by tiling `x` by `n`.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable\n",
      "            n: A list of integer. The length must be the same as the number of\n",
      "                dimensions in `x`.\n",
      "        \n",
      "        Returns:\n",
      "            A tiled tensor.\n",
      "    \n",
      "    to_dense(tensor)\n",
      "        Converts a sparse tensor into a dense tensor and returns it.\n",
      "        \n",
      "        Arguments:\n",
      "            tensor: A tensor instance (potentially sparse).\n",
      "        \n",
      "        Returns:\n",
      "            A dense tensor.\n",
      "        \n",
      "        Examples:\n",
      "        ```python\n",
      "            >>> from keras import backend as K\n",
      "            >>> b = K.placeholder((2, 2), sparse=True)\n",
      "            >>> print(K.is_sparse(b))\n",
      "            True\n",
      "            >>> c = K.to_dense(b)\n",
      "            >>> print(K.is_sparse(c))\n",
      "            False\n",
      "        ```\n",
      "    \n",
      "    transpose(x)\n",
      "        Transposes a tensor and returns it.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Tensor or variable.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "        \n",
      "        Examples:\n",
      "        ```python\n",
      "            >>> var = K.variable([[1, 2, 3], [4, 5, 6]])\n",
      "            >>> K.eval(var)\n",
      "            array([[ 1.,  2.,  3.],\n",
      "                   [ 4.,  5.,  6.]], dtype=float32)\n",
      "            >>> var_transposed = K.transpose(var)\n",
      "            >>> K.eval(var_transposed)\n",
      "            array([[ 1.,  4.],\n",
      "                   [ 2.,  5.],\n",
      "                   [ 3.,  6.]], dtype=float32)\n",
      "        ```\n",
      "        \n",
      "        ```python\n",
      "            >>> input = K.placeholder((2, 3))\n",
      "            >>> input\n",
      "            <tf.Tensor 'Placeholder_11:0' shape=(2, 3) dtype=float32>\n",
      "            >>> input_transposed = K.transpose(input)\n",
      "            >>> input_transposed\n",
      "            <tf.Tensor 'transpose_4:0' shape=(3, 2) dtype=float32>\n",
      "        \n",
      "        ```\n",
      "    \n",
      "    truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None)\n",
      "        Returns a tensor with truncated random normal distribution of values.\n",
      "        \n",
      "        The generated values follow a normal distribution\n",
      "        with specified mean and standard deviation,\n",
      "        except that values whose magnitude is more than\n",
      "        two standard deviations from the mean are dropped and re-picked.\n",
      "        \n",
      "        Arguments:\n",
      "            shape: A tuple of integers, the shape of tensor to create.\n",
      "            mean: Mean of the values.\n",
      "            stddev: Standard deviation of the values.\n",
      "            dtype: String, dtype of returned tensor.\n",
      "            seed: Integer, random seed.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor.\n",
      "    \n",
      "    update(x, new_x)\n",
      "    \n",
      "    update_add(x, increment)\n",
      "    \n",
      "    update_sub(x, decrement)\n",
      "    \n",
      "    var(x, axis=None, keepdims=False)\n",
      "        Variance of a tensor, alongside the specified axis.\n",
      "        \n",
      "        Arguments:\n",
      "            x: A tensor or variable.\n",
      "            axis: An integer, the axis to compute the variance.\n",
      "            keepdims: A boolean, whether to keep the dimensions or not.\n",
      "                If `keepdims` is `False`, the rank of the tensor is reduced\n",
      "                by 1. If `keepdims` is `True`,\n",
      "                the reduced dimension is retained with length 1.\n",
      "        \n",
      "        Returns:\n",
      "            A tensor with the variance of elements of `x`.\n",
      "    \n",
      "    variable(value, dtype=None, name=None)\n",
      "        Instantiates a variable and returns it.\n",
      "        \n",
      "        Arguments:\n",
      "            value: Numpy array, initial value of the tensor.\n",
      "            dtype: Tensor type.\n",
      "            name: Optional name string for the tensor.\n",
      "        \n",
      "        Returns:\n",
      "            A variable instance (with Keras metadata included).\n",
      "        \n",
      "        Examples:\n",
      "        ```python\n",
      "            >>> from keras import backend as K\n",
      "            >>> val = np.array([[1, 2], [3, 4]])\n",
      "            >>> kvar = K.variable(value=val, dtype='float64', name='example_var')\n",
      "            >>> K.dtype(kvar)\n",
      "            'float64'\n",
      "            >>> print(kvar)\n",
      "            example_var\n",
      "            >>> kvar.eval()\n",
      "            array([[ 1.,  2.],\n",
      "                   [ 3.,  4.]])\n",
      "        ```\n",
      "    \n",
      "    zeros(shape, dtype=None, name=None)\n",
      "        Instantiates an all-zeros variable and returns it.\n",
      "        \n",
      "        Arguments:\n",
      "            shape: Tuple of integers, shape of returned Keras variable\n",
      "            dtype: String, data type of returned Keras variable\n",
      "            name: String, name of returned Keras variable\n",
      "        \n",
      "        Returns:\n",
      "            A variable (including Keras metadata), filled with `0.0`.\n",
      "        \n",
      "        Example:\n",
      "        ```python\n",
      "            >>> from keras import backend as K\n",
      "            >>> kvar = K.zeros((3,4))\n",
      "            >>> K.eval(kvar)\n",
      "            array([[ 0.,  0.,  0.,  0.],\n",
      "                   [ 0.,  0.,  0.,  0.],\n",
      "                   [ 0.,  0.,  0.,  0.]], dtype=float32)\n",
      "        ```\n",
      "    \n",
      "    zeros_like(x, dtype=None, name=None)\n",
      "        Instantiates an all-zeros variable of the same shape as another tensor.\n",
      "        \n",
      "        Arguments:\n",
      "            x: Keras variable or Keras tensor.\n",
      "            dtype: String, dtype of returned Keras variable.\n",
      "                 None uses the dtype of x.\n",
      "            name: String, name for the variable to create.\n",
      "        \n",
      "        Returns:\n",
      "            A Keras variable with the shape of x filled with zeros.\n",
      "        \n",
      "        Example:\n",
      "        ```python\n",
      "            >>> from keras import backend as K\n",
      "            >>> kvar = K.variable(np.random.random((2,3)))\n",
      "            >>> kvar_zeros = K.zeros_like(kvar)\n",
      "            >>> K.eval(kvar_zeros)\n",
      "            array([[ 0.,  0.,  0.],\n",
      "                   [ 0.,  0.,  0.]], dtype=float32)\n",
      "        ```\n",
      "\n",
      "DATA\n",
      "    __warningregistry__ = {'version': 40, (\"unclosed file <_io.TextIOWrapp...\n",
      "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
      "    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192...\n",
      "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
      "\n",
      "FILE\n",
      "    /home/ad_rmongemo/anaconda/lib/python3.6/site-packages/tensorflow/contrib/keras/python/keras/backend.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(K)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
